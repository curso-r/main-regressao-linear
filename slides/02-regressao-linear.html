<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Regressão Linear</title>
    <meta charset="utf-8" />
    <meta name="author" content="" />
    <meta name="date" content="2021-01-08" />
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <link href="libs/remark-css/default-fonts.css" rel="stylesheet" />
    <script src="libs/htmlwidgets/htmlwidgets.js"></script>
    <script src="libs/plotly-binding/plotly.js"></script>
    <script src="libs/typedarray/typedarray.min.js"></script>
    <script src="libs/jquery/jquery.min.js"></script>
    <link href="libs/crosstalk/css/crosstalk.css" rel="stylesheet" />
    <script src="libs/crosstalk/js/crosstalk.min.js"></script>
    <link href="libs/plotly-htmlwidgets-css/plotly-htmlwidgets.css" rel="stylesheet" />
    <script src="libs/plotly-main/plotly-latest.min.js"></script>
    <script src="libs/kePrint/kePrint.js"></script>
    <link rel="stylesheet" href="css/custom-regressao-linear.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Regressão Linear
## Teoria e Prática
### <img src = 'https://d33wubrfki0l68.cloudfront.net/9b0699f18268059bdd2e5c21538a29eade7cbd2b/67e5c/img/logo/cursor1-5.png' width = '20%'>
### 2021-01-08

---





## Agenda

.pull-left[
- O que é e quando usar
- Parâmetro vs estimador
- Teste de Hipóteses e valor-p
- Interpretação dos parâmetros
- Desempenho: EQM e EPR
- Outliers
- Regressão Linear Múltipla
- Preditores Categóricos
- Transformações Não Lineares dos Preditores
- Interações
- Multicolinearidade
- Fazendo Predições
- Interpretabilidade da Predição
- Limitações da Regressão Linear
- Exercício para casa

]

.pull-right[

- Sobreajuste (overfitting)
- Regularização
- LASSO e Seleção de Preditores
- Validação Cruzada

]


---

## Referências

- [Aprendizagem de Máquinas: Uma Abordagem Estatística (Rafael Izbicki e Thiago Mendonça, 2020)](http://www.rizbicki.ufscar.br/AME.pdf)

- [Introduction to Statistical Learning (Hastie, et al)](http://faculty.marshall.usc.edu/gareth-james/ISL/ISLR%20Seventh%20Printing.pdf)

- [Ciência de Dados: Fundamentos e Aplicações](https://curso-r.github.io/main-regressao-linear/referencias/Ci%C3%AAncia%20de%20Dados.%20Fundamentos%20e%20Aplica%C3%A7%C3%B5es.%20Vers%C3%A3o%20parcial%20preliminar.%20maio%20Pedro%20A.%20Morettin%20Julio%20M.%20Singer.pdf)

---

## O que é e quando usar


.pull-left[

### Regressão Linear Simples

$$
y = \beta_0 + \beta_1x
$$

### Exemplo: 

$$
dist = \beta_0 + \beta_1speed
$$


]


.pull-right[

![](02-regressao-linear_files/figure-html/unnamed-chunk-1-1.png)&lt;!-- --&gt;

]


.footnote[
Ver [ISL](https://www.ime.unicamp.br/~dias/Intoduction%20to%20Statistical%20Learning.pdf) página 61 (Simple Linear Regression).
]



---

## O que é e quando usar


.pull-left[

### Regressão Linear Simples

$$
y = \beta_0 + \beta_1x
$$

### Exemplo: 

$$
dist = \beta_0 + \beta_1speed
$$


]


.pull-right[

![](02-regressao-linear_files/figure-html/unnamed-chunk-2-1.png)&lt;!-- --&gt;

]


.footnote[
Ver [ISL](https://www.ime.unicamp.br/~dias/Intoduction%20to%20Statistical%20Learning.pdf) página 61 (Simple Linear Regression).
]



---

## O que é e quando usar


.pull-left[

### Regressão Linear Simples

$$
y = \beta_0 + \beta_1x
$$

### Exemplo: 

$$
dist = \beta_0 + \beta_1speed
$$


]


.pull-right[

![](02-regressao-linear_files/figure-html/unnamed-chunk-3-1.png)&lt;!-- --&gt;

]

.footnote[
Ver [ISL](https://www.ime.unicamp.br/~dias/Intoduction%20to%20Statistical%20Learning.pdf) página 61 (Simple Linear Regression).
]


---

## O que é e quando usar


.pull-left[

### Regressão Linear Simples

$$
y = \beta_0 + \beta_1x
$$

]


.pull-right[


]


```r
# ajuste de uma regressão linear simples no R
*melhor_reta &lt;- lm(dist ~ speed, data = cars)
melhor_reta
```

```
## 
## Call:
## lm(formula = dist ~ speed, data = cars)
## 
## Coefficients:
## (Intercept)        speed  
##     -17.579        3.932
```



.footnote[
Ver [ISL](https://www.ime.unicamp.br/~dias/Intoduction%20to%20Statistical%20Learning.pdf) página 61 (Simple Linear Regression).
]

---

## "Melhor Reta" segundo o quê?

Queremos a reta que **erre menos**.

Uma medida de erro: **E**rro **Q**uadrático **M**édio.

$$
EQM = \frac{1}{N}\sum(y_i - \hat{y_i})^2
$$

---

## "Melhor Reta" segundo o quê?

Queremos a reta que **erre menos**.

Uma medida de erro: **E**rro **Q**uadrático **M**édio.

$$
EQM = \frac{1}{N}\sum(y_i - (\hat{\beta_0} + \hat{\beta_1}x))^2
$$
--

![](02-regressao-linear_files/figure-html/unnamed-chunk-5-1.png)&lt;!-- --&gt;




---

## "Melhor Reta" segundo o quê?

Queremos a reta que **erre menos**.

Uma medida de erro: **E**rro **Q**uadrático **M**édio.

$$
EQM = \frac{1}{N}\sum(y_i - \hat{y_i})^2
$$

Ou seja, nosso **objetivo** é

## Encontrar `\(\hat{\beta}_0\)` e `\(\hat{\beta}_1\)` que nos retorne o ~menor~ EQM.

--

... que é o mesmo que dizer "encontrar a melhor reta que explique os dados".

OBS: o EQM é a nossa **Função de Custo**.


```r
# lembrete: exercício 1 do script!
```


---

## Qual o valor ótimo para `\(\beta_0\)` e `\(\beta_1\)`?

No nosso exemplo, a nossa **HIPÓTESE** é de que 

$$
dist = \beta_0 + \beta_1speed
$$

Então podemos escrever o Erro Quadrático Médio como

$$
EQM = \frac{1}{N}\sum(y_i - \hat{y_i})^2 = \frac{1}{N}\sum(y_i -  \color{red}{(\hat{\beta}_0 + \hat{\beta}_1speed)})^2 
$$

Com ajuda do Cálculo é possível mostrar que os valores ótimos para `\(\beta_0\)` e `\(\beta_1\)` são

`\(\hat{\beta}_1 = \frac{\sum(x_i - \bar{x})(y_i - \bar{y})}{\sum(x_i - \bar{x})^2}\)`

`\(\hat{\beta}_0 = \bar{y} - \hat{\beta}_1\bar{x}\)`

Já que vieram do EQM, eles são chamados de **Estimadores de Mínimos Quadrados**.


```r
# lembrete: exercício 2 do script!
```



---

## Depois de estimar...

$$
\hat{y} = \hat{\beta}_0 + \hat{\beta}_1x
$$

### Exemplo:

$$
\hat{dist} = \hat{\beta}_0 + \hat{\beta}_1speed
$$

Colocamos um `\(\hat{}\)` em cima dos termos para representar "estimativas". Ou seja, `\(\hat{y}_i\)` é uma estimativa de `\(y_i\)`.

No nosso exemplo, 

- `\(\hat{\beta}_0\)` é uma estimativa de `\(\beta_0\)` e vale `-17.579`.
- `\(\hat{\beta}_1\)` é uma estimativa de `\(\beta_1\)` e vale `3.932`.
- `\(\hat{dist}\)` é uma estimativa de `\(dist\)` e vale `-17.579 + 3.932 x speed`.


```r
# Exercício: se speed for 15 m/h, quanto que 
# seria a distância dist esperada?
```

---

## Teste de Hipóteses e valor-p

Exemplo: relação entre População Urbana e Assassinatos.

.pull-left[

![](02-regressao-linear_files/figure-html/unnamed-chunk-9-1.png)&lt;!-- --&gt;

Modelo proposto: 

`$$y = \beta_0 + \beta_1 x$$`

]

.pull-right[

Hipótese do pesquisador: 
&gt; "Assassinatos não estão relacionados com a proporção de população urbana de uma cidade."

Tradução da hipótese em termos matemáticos:

$$
H_0: \beta_1 = 0 \space\space\space\space\space vs \space\space\space\space H_a: \beta_1 \neq 0
$$
Se a hipótese for verdade, então o `\(\beta_1\)` deveria ser zero. Porém, os dados disseram que `\(\hat{\beta}_1 = 0.02\)`. 

### 0.02 é diferente de 0.00? 

]



---

## 0.02 é diferente de 0.00? 

### Saída do R


```
## 
## Call:
## lm(formula = Murder ~ UrbanPop, data = USArrests)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -6.537 -3.736 -0.779  3.332  9.728 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)  
## (Intercept)  6.41594    2.90669   2.207   0.0321 *
*## UrbanPop     0.02093    0.04333   0.483   0.6312  
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 4.39 on 48 degrees of freedom
## Multiple R-squared:  0.00484,	Adjusted R-squared:  -0.01589 
## F-statistic: 0.2335 on 1 and 48 DF,  p-value: 0.6312
```



---

## 0.02 é diferente de 0.00? 

Conceito importante: Os estimadores ( `\(\hat{\beta}_0\)` e `\(\hat{\beta}_1\)` no nosso caso) têm distribuições de probabilidade.

### Simulação de 1000 retas (ajustadas com dados diferentes).

![distrib_params](img/combined_gif.gif)


---

## 0.02 é diferente de 0.00? 

Conceito importante: Os estimadores ( `\(\hat{\beta}_0\)` e `\(\hat{\beta}_1\)` no nosso caso) têm distribuições de probabilidade.

### A Teoria Assintótica nos fornece o seguinte resultado:


.pull-left[

`\(t = \frac{\hat{\beta_1} - \beta_1}{\hat{\sigma}_{\beta_1}} \overset{\text{a}}{\sim}  t(N - 2)\)`

#### Em que

`\(\hat{\sigma}_{\beta_1} = \sqrt{\frac{EQM}{\sum(x_i - \bar{x})^2}}\)`


Usamos essas distribuições assintóticas para testar as hipóteses.

]

.pull-right[

&lt;div style="width:200px; height:100px"&gt;
&lt;img src="img/dnorm_params.png"&gt;
&lt;/div&gt;

]


---


## 0.02 é diferente de 0.00? 

Conceito importante: Os estimadores ( `\(\hat{\beta}_0\)` e `\(\hat{\beta}_1\)` no nosso caso) têm distribuições de probabilidade.

### A Teoria Assintótica nos fornece o seguinte resultado:


.pull-left[


`\(t = \frac{\hat{\beta_1} - \beta_1}{\hat{\sigma}_{\beta_1}} \overset{\text{a}}{\sim}  t(N - 2)\)`

#### Em que

`\(\hat{\sigma}_{\beta_1} = \sqrt{\frac{EQM}{\sum(x_i - \bar{x})^2}}\)`

Usamos essas distribuições assintóticas para testar as hipóteses.

]

.pull-right[

No nosso exemplo, a hipótese é `\(H_0: \beta_1 = 0\)`, então 

`$$t = \frac{0.02 - 0}{0.04} = 0.48$$`

![](02-regressao-linear_files/figure-html/unnamed-chunk-11-1.png)&lt;!-- --&gt;


]



---

## 0.02 é diferente de 0.00? 

Então agora podemos tomar decisão! Se a estimativa cair muito distante da distribuição t da hipótese 0, decidimos por **rejeitá-la**. Caso contrário, decidimos por **aceitá-la** como verdade.

![testes_t_estrelas](img/testes_t_estrelas.png)


```
## NO R:
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)  
## (Intercept)  6.41594    2.90669   2.207   0.0321 *
## UrbanPop     0.02093    0.04333   0.483   0.6312  
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
```

---

## Interpretação dos parâmetros

.pull-left[

![](02-regressao-linear_files/figure-html/unnamed-chunk-13-1.png)&lt;!-- --&gt;

$$
y = \color{darkgblue}{\beta_0} + \color{darkgreen}{\beta_1}x
$$

]

.pull-right[

### Interpretações matemáticas

`\(\color{darkgblue}{\beta_0}\)` é o lugar em que a reta cruza o eixo Y.

`\(\color{darkgreen}{\beta_1}\)` é a derivada de Y em relação ao X. É quanto Y varia quando X varia em 1 unidade.

### Interpretações estatísticas

`\(\color{darkgblue}{\beta_0}\)` é a distância percorrida esperada quando o carro está parado (X = 0).

`\(\color{darkgreen}{\beta_1}\)` é o efeito médio na distância por variar 1 ml/h na velocidade do carro.


]



---

## Teste de Hipóteses e valor-p 

### Exercício 3 do script: 

No R, use a função `summary(melhor_reta)` (ver slide 9) para decidir se `speed` está associado com `dist`. Descubra o valor-p associado.

lembrete: o banco de dados se chama `cars`.

### Exercício 4 do script: 

Interprete o parâmetro `\(\beta_1\)`.

---

## Intervalo de confiança para `\(\beta_1\)`

#### Intervalo de 95%
`$$[\hat{\beta} - 1,96 * \hat{\sigma}_{\beta_1}, \hat{\beta} + 1,96 * \hat{\sigma}_{\beta_1}]$$`

#### Intervalo de 90%
`$$[\hat{\beta} - 1,64 * \hat{\sigma}_{\beta_1}, \hat{\beta} + 1,64 * \hat{\sigma}_{\beta_1}]$$`

#### Intervalo de 1 - `\(\alpha\)`%

`$$[\hat{\beta}_1 - q_{\alpha} * \hat{\sigma}_{\beta_1}, \hat{\beta} + q_{\alpha} * \hat{\sigma}_{\beta_1}]$$`

em que `\(q_\alpha\)` é o quantil da `\(Normal(0, 1)\)`.

.footnote[
Ver [ISL](https://www.ime.unicamp.br/~dias/Intoduction%20to%20Statistical%20Learning.pdf) página 66 (Assessing the Accuracy of the Model).
]


---

## O modelo está bom?

### EQM e EPR

ERP significa *E*rro *P*adrão dos *R*esíduos e é definido como 

$$
EPR = \frac{\sum(y_i - \hat{y_i})^2}{N - 2} = \frac{SQR}{N - 2}
$$
O **2** no denominador decorre do fato de termos **2 parâmetros** para estimar no modelo.

- Se `\(y_i = \hat{y}_i \space\space\space \rightarrow \color{green}{EPR = 0 \downarrow}\)`
- Se `\(y_i &gt;&gt; \hat{y}_i \rightarrow \color{red}{EPR = alto \uparrow}\)`
- Se `\(y_i &lt;&lt; \hat{y}_i \rightarrow \color{red}{EPR = alto \uparrow}\)`


Problema: Como sabemos se o EPR é grande ou pequeno?

.footnote[
Ver [ISL](https://www.ime.unicamp.br/~dias/Intoduction%20to%20Statistical%20Learning.pdf) página 68 (Assessing the Accuracy of the Model).

]


---

## O modelo está bom?

### R-quadrado ( `\(R^2\)` )

$$
R^2 = 1 - \frac{\sum(y_i - \color{salmon}{\hat{y_i}})^2}{\sum(y_i - \color{royalblue}{\bar{y}})^2} = 1 - \frac{\color{salmon}{SQR}}{\color{royalblue}{SQT}}
$$

.pull-left[

&lt;img src="02-regressao-linear_files/figure-html/unnamed-chunk-14-1.png" style="display: block; margin: auto;" /&gt;

]

.pull-right[

`\(R^2 \approx 1 \rightarrow \color{salmon}{SQR} &lt;&lt; \color{royalblue}{SQT}\)`.
`\(R^2 \approx 0 \rightarrow \color{salmon}{reta} \text{ em cima da } \color{royalblue}{reta}\)`.

Problema do `\(R^2\)` é que ele sempre aumenta conforme novos preditores vão sendo incluídos.

]






.footnote[
Ver [ISL](https://www.ime.unicamp.br/~dias/Intoduction%20to%20Statistical%20Learning.pdf) página 68 (Assessing the Accuracy of the Model).
]

---

## O modelo está bom?

### R-quadrado ajustado

$$
R^2 = 1 - \frac{\color{salmon}{SQR}}{\color{royalblue}{SQT}}\frac{\color{royalblue}{N-1}}{\color{salmon}{N-p}}
$$

Em que `\(p\)` é o número de parâmetros do modelo (no caso da regressão linear simples, `\(p = 2\)`).


```r
# lembrete: exercícios 5 e 6 do script!
```

---

## Outliers

&lt;img src="02-regressao-linear_files/figure-html/unnamed-chunk-16-1.png" style="display: block; margin: auto;" /&gt;

Resíduo = `\(y_i - \hat{y}_i\)` (observado - esperado).


```r
# lembrete: faça o exercício 7 do script
```

.footnote[
Ver [ISL](https://www.ime.unicamp.br/~dias/Intoduction%20to%20Statistical%20Learning.pdf) página 96 (Outliers).
]



---

## Outliers

&lt;img src="02-regressao-linear_files/figure-html/unnamed-chunk-18-1.png" style="display: block; margin: auto;" /&gt;

Resíduo = `\(y_i - \hat{y}_i\)` (observado - esperado).


```r
# lembrete: faça o exercício 7 do script
```

.footnote[
Ver [ISL](https://www.ime.unicamp.br/~dias/Intoduction%20to%20Statistical%20Learning.pdf) página 96 (Outliers).
]

---

## Outliers

&lt;img src="02-regressao-linear_files/figure-html/unnamed-chunk-20-1.png" style="display: block; margin: auto;" /&gt;

.footnote[
Ver [ISL](https://www.ime.unicamp.br/~dias/Intoduction%20to%20Statistical%20Learning.pdf) página 96 (Outliers).
]

---

## Outliers

&lt;img src="02-regressao-linear_files/figure-html/unnamed-chunk-21-1.png" style="display: block; margin: auto;" /&gt;

.footnote[
Ver [ISL](https://www.ime.unicamp.br/~dias/Intoduction%20to%20Statistical%20Learning.pdf) página 96 (Outliers).
]


---

## Outliers

### Distância de Cook

.pull-left[

A distância de Cook mede o efeito de excluir uma dada observação.

`$$D_i = \frac{\sum_{j=1}^{n}(\hat{y}_j - \hat{y}_{j(i)})^2}{p EQM}$$`


```r
modelo &lt;- lm(dist ~ speed, data = cars)
plot(modelo)
cooks.distance(modelo)
```
]

.pull-right[

![](02-regressao-linear_files/figure-html/unnamed-chunk-23-1.png)&lt;!-- --&gt;

]


.footnote[
Ver [Distância de Cook na Wikipedia](https://pt.wikipedia.org/wiki/Dist%C3%A2ncia_de_Cook).
]


---

## Outliers

### Diagnóstico

- Visualização univariada (histograma, boxplot);

- Comparação do valor com o desvio padrão;

- Distância de Cook

### Tratamentos

- Transformações log(), etc;

- Categorização;

- Remover os valores extremos (raramente boa ideia);




---

## Regressão Linear Múltipla

### Regressão Linear Simples

$$
y = \beta_0 + \beta_1x
$$

### Regressão Linear Múltipla

$$
y = \beta_0 + \beta_1x_1 + \beta_2x_2 + \dots + \beta_px_p
$$


```r
# ajuste de uma regressão linear múltipla no R
*modelo_boston &lt;- lm(medv ~ lstat + age, data = Boston)
summary(modelo_boston)
#             Estimate Std.Error t value Pr(&gt;|t|)    
# (Intercept) 33.22    0.73      45.4    &lt; 2e-16 ***
# lstat       -1.03    0.04     -21.4    &lt; 2e-16 ***
# age          0.03    0.01       2.8    0.00491 ** 
```

.footnote[
Ver [ISL](https://www.ime.unicamp.br/~dias/Intoduction%20to%20Statistical%20Learning.pdf) página 71 (Multiple Linear Regression).
]


---

## Regressão Linear Múltipla

### Exemplo: Plano em vez de reta

Modelo: `lm(mpg ~ disp + wt, data = mtcars)`


<div id="htmlwidget-55ecbaa9f131310e314a" style="width:600px;height:360px;" class="plotly html-widget"></div>
<script type="application/json" data-for="htmlwidget-55ecbaa9f131310e314a">{"x":{"visdat":{"427405b16d12e":["function () ","plotlyVisDat"]},"cur_data":"427405b16d12e","attrs":{"427405b16d12e":{"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"x":{},"y":{},"z":{},"type":"scatter3d","mode":"markers","opacity":0.8,"inherit":true},"427405b16d12e.1":{"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"z":[[28.6305259890832,28.3462919899241,28.062057990765,27.777823991606,27.4935899924469,27.2093559932878,26.9251219941288,26.6408879949697,26.3566539958106,26.0724199966515,25.7881859974925,25.5039519983334,25.2197179991743,24.9354840000153,24.6512500008562,24.3670160016971,24.082782002538,23.798548003379,23.5143140042199,23.2300800050608,22.9458460059018,22.6616120067427,22.3773780075836,22.0931440084245,21.8089100092655,21.5246760101064],[28.1063228739342,27.8220888747751,27.537854875616,27.253620876457,26.9693868772979,26.6851528781388,26.4009188789797,26.1166848798207,25.8324508806616,25.5482168815025,25.2639828823435,24.9797488831844,24.6955148840253,24.4112808848662,24.1270468857072,23.8428128865481,23.558578887389,23.27434488823,22.9901108890709,22.7058768899118,22.4216428907527,22.1374088915937,21.8531748924346,21.5689408932755,21.2847068941165,21.0004728949574],[27.5821197587852,27.2978857596261,27.013651760467,26.7294177613079,26.4451837621489,26.1609497629898,25.8767157638307,25.5924817646717,25.3082477655126,25.0240137663535,24.7397797671944,24.4555457680354,24.1713117688763,23.8870777697172,23.6028437705582,23.3186097713991,23.03437577224,22.7501417730809,22.4659077739219,22.1816737747628,21.8974397756037,21.6132057764447,21.3289717772856,21.0447377781265,20.7605037789674,20.4762697798084],[27.0579166436362,26.7736826444771,26.489448645318,26.2052146461589,25.9209806469999,25.6367466478408,25.3525126486817,25.0682786495227,24.7840446503636,24.4998106512045,24.2155766520454,23.9313426528864,23.6471086537273,23.3628746545682,23.0786406554092,22.7944066562501,22.510172657091,22.2259386579319,21.9417046587729,21.6574706596138,21.3732366604547,21.0890026612957,20.8047686621366,20.5205346629775,20.2363006638184,19.9520666646594],[26.5337135284871,26.2494795293281,25.965245530169,25.6810115310099,25.3967775318509,25.1125435326918,24.8283095335327,24.5440755343736,24.2598415352146,23.9756075360555,23.6913735368964,23.4071395377374,23.1229055385783,22.8386715394192,22.5544375402601,22.2702035411011,21.985969541942,21.7017355427829,21.4175015436239,21.1332675444648,20.8490335453057,20.5647995461466,20.2805655469876,19.9963315478285,19.7120975486694,19.4278635495104],[26.0095104133381,25.7252764141791,25.44104241502,25.1568084158609,24.8725744167018,24.5883404175428,24.3041064183837,24.0198724192246,23.7356384200656,23.4514044209065,23.1671704217474,22.8829364225883,22.5987024234293,22.3144684242702,22.0302344251111,21.7460004259521,21.461766426793,21.1775324276339,20.8932984284748,20.6090644293158,20.3248304301567,20.0405964309976,19.7563624318386,19.4721284326795,19.1878944335204,18.9036604343613],[25.4853072981891,25.20107329903,24.916839299871,24.6326053007119,24.3483713015528,24.0641373023938,23.7799033032347,23.4956693040756,23.2114353049165,22.9272013057575,22.6429673065984,22.3587333074393,22.0744993082803,21.7902653091212,21.5060313099621,21.221797310803,20.937563311644,20.6533293124849,20.3690953133258,20.0848613141668,19.8006273150077,19.5163933158486,19.2321593166895,18.9479253175305,18.6636913183714,18.3794573192123],[24.9611041830401,24.676870183881,24.392636184722,24.1084021855629,23.8241681864038,23.5399341872448,23.2557001880857,22.9714661889266,22.6872321897675,22.4029981906085,22.1187641914494,21.8345301922903,21.5502961931313,21.2660621939722,20.9818281948131,20.697594195654,20.413360196495,20.1291261973359,19.8448921981768,19.5606581990178,19.2764241998587,18.9921902006996,18.7079562015405,18.4237222023815,18.1394882032224,17.8552542040633],[24.4369010678911,24.152667068732,23.868433069573,23.5841990704139,23.2999650712548,23.0157310720957,22.7314970729367,22.4472630737776,22.1630290746185,21.8787950754595,21.5945610763004,21.3103270771413,21.0260930779822,20.7418590788232,20.4576250796641,20.173391080505,19.889157081346,19.6049230821869,19.3206890830278,19.0364550838687,18.7522210847097,18.4679870855506,18.1837530863915,17.8995190872325,17.6152850880734,17.3310510889143],[23.9126979527421,23.628463953583,23.344229954424,23.0599959552649,22.7757619561058,22.4915279569467,22.2072939577877,21.9230599586286,21.6388259594695,21.3545919603105,21.0703579611514,20.7861239619923,20.5018899628332,20.2176559636742,19.9334219645151,19.649187965356,19.3649539661969,19.0807199670379,18.7964859678788,18.5122519687197,18.2280179695607,17.9437839704016,17.6595499712425,17.3753159720834,17.0910819729244,16.8068479737653],[23.3884948375931,23.104260838434,22.8200268392749,22.5357928401159,22.2515588409568,21.9673248417977,21.6830908426387,21.3988568434796,21.1146228443205,20.8303888451614,20.5461548460024,20.2619208468433,19.9776868476842,19.6934528485252,19.4092188493661,19.124984850207,18.8407508510479,18.5565168518889,18.2722828527298,17.9880488535707,17.7038148544117,17.4195808552526,17.1353468560935,16.8511128569344,16.5668788577754,16.2826448586163],[22.8642917224441,22.580057723285,22.2958237241259,22.0115897249669,21.7273557258078,21.4431217266487,21.1588877274896,20.8746537283306,20.5904197291715,20.3061857300124,20.0219517308534,19.7377177316943,19.4534837325352,19.1692497333761,18.8850157342171,18.600781735058,18.3165477358989,18.0323137367399,17.7480797375808,17.4638457384217,17.1796117392626,16.8953777401036,16.6111437409445,16.3269097417854,16.0426757426264,15.7584417434673],[22.3400886072951,22.055854608136,21.7716206089769,21.4873866098178,21.2031526106588,20.9189186114997,20.6346846123406,20.3504506131816,20.0662166140225,19.7819826148634,19.4977486157043,19.2135146165453,18.9292806173862,18.6450466182271,18.3608126190681,18.076578619909,17.7923446207499,17.5081106215908,17.2238766224318,16.9396426232727,16.6554086241136,16.3711746249546,16.0869406257955,15.8027066266364,15.5184726274773,15.2342386283183],[21.8158854921461,21.531651492987,21.2474174938279,20.9631834946688,20.6789494955098,20.3947154963507,20.1104814971916,19.8262474980326,19.5420134988735,19.2577794997144,18.9735455005553,18.6893115013963,18.4050775022372,18.1208435030781,17.8366095039191,17.55237550476,17.2681415056009,16.9839075064418,16.6996735072828,16.4154395081237,16.1312055089646,15.8469715098056,15.5627375106465,15.2785035114874,14.9942695123283,14.7100355131693],[21.291682376997,21.007448377838,20.7232143786789,20.4389803795198,20.1547463803608,19.8705123812017,19.5862783820426,19.3020443828835,19.0178103837245,18.7335763845654,18.4493423854063,18.1651083862473,17.8808743870882,17.5966403879291,17.31240638877,17.028172389611,16.7439383904519,16.4597043912928,16.1754703921338,15.8912363929747,15.6070023938156,15.3227683946565,15.0385343954975,14.7543003963384,14.4700663971793,14.1858323980203],[20.767479261848,20.483245262689,20.1990112635299,19.9147772643708,19.6305432652117,19.3463092660527,19.0620752668936,18.7778412677345,18.4936072685755,18.2093732694164,17.9251392702573,17.6409052710982,17.3566712719392,17.0724372727801,16.788203273621,16.503969274462,16.2197352753029,15.9355012761438,15.6512672769847,15.3670332778257,15.0827992786666,14.7985652795075,14.5143312803485,14.2300972811894,13.9458632820303,13.6616292828712],[20.243276146699,19.95904214754,19.6748081483809,19.3905741492218,19.1063401500627,18.8221061509037,18.5378721517446,18.2536381525855,17.9694041534265,17.6851701542674,17.4009361551083,17.1167021559492,16.8324681567902,16.5482341576311,16.264000158472,15.979766159313,15.6955321601539,15.4112981609948,15.1270641618357,14.8428301626767,14.5585961635176,14.2743621643585,13.9901281651995,13.7058941660404,13.4216601668813,13.1374261677222],[19.71907303155,19.4348390323909,19.1506050332319,18.8663710340728,18.5821370349137,18.2979030357547,18.0136690365956,17.7294350374365,17.4452010382774,17.1609670391184,16.8767330399593,16.5924990408002,16.3082650416412,16.0240310424821,15.739797043323,15.4555630441639,15.1713290450049,14.8870950458458,14.6028610466867,14.3186270475277,14.0343930483686,13.7501590492095,13.4659250500504,13.1816910508914,12.8974570517323,12.6132230525732],[19.194869916401,18.9106359172419,18.6264019180829,18.3421679189238,18.0579339197647,17.7736999206056,17.4894659214466,17.2052319222875,16.9209979231284,16.6367639239694,16.3525299248103,16.0682959256512,15.7840619264921,15.4998279273331,15.215593928174,14.9313599290149,14.6471259298559,14.3628919306968,14.0786579315377,13.7944239323786,13.5101899332196,13.2259559340605,12.9417219349014,12.6574879357424,12.3732539365833,12.0890199374242],[18.670666801252,18.3864328020929,18.1021988029338,17.8179648037748,17.5337308046157,17.2494968054566,16.9652628062976,16.6810288071385,16.3967948079794,16.1125608088204,15.8283268096613,15.5440928105022,15.2598588113431,14.9756248121841,14.691390813025,14.4071568138659,14.1229228147069,13.8386888155478,13.5544548163887,13.2702208172296,12.9859868180706,12.7017528189115,12.4175188197524,12.1332848205933,11.8490508214343,11.5648168222752],[18.146463686103,17.8622296869439,17.5779956877848,17.2937616886258,17.0095276894667,16.7252936903076,16.4410596911486,16.1568256919895,15.8725916928304,15.5883576936713,15.3041236945123,15.0198896953532,14.7356556961941,14.4514216970351,14.167187697876,13.8829536987169,13.5987196995578,13.3144857003988,13.0302517012397,12.7460177020806,12.4617837029216,12.1775497037625,11.8933157046034,11.6090817054443,11.3248477062853,11.0406137071262],[17.622260570954,17.3380265717949,17.0537925726358,16.7695585734768,16.4853245743177,16.2010905751586,15.9168565759995,15.6326225768405,15.3483885776814,15.0641545785223,14.7799205793633,14.4956865802042,14.2114525810451,13.927218581886,13.642984582727,13.3587505835679,13.0745165844088,12.7902825852498,12.5060485860907,12.2218145869316,11.9375805877725,11.6533465886135,11.3691125894544,11.0848785902953,10.8006445911363,10.5164105919772],[17.098057455805,16.8138234566459,16.5295894574868,16.2453554583277,15.9611214591687,15.6768874600096,15.3926534608505,15.1084194616915,14.8241854625324,14.5399514633733,14.2557174642142,13.9714834650552,13.6872494658961,13.403015466737,13.118781467578,12.8345474684189,12.5503134692598,12.2660794701007,11.9818454709417,11.6976114717826,11.4133774726235,11.1291434734645,10.8449094743054,10.5606754751463,10.2764414759872,9.99220747682818],[16.573854340656,16.2896203414969,16.0053863423378,15.7211523431787,15.4369183440197,15.1526843448606,14.8684503457015,14.5842163465425,14.2999823473834,14.0157483482243,13.7315143490652,13.4472803499062,13.1630463507471,12.878812351588,12.594578352429,12.3103443532699,12.0261103541108,11.7418763549517,11.4576423557927,11.1734083566336,10.8891743574745,10.6049403583155,10.3207063591564,10.0364723599973,9.75223836083824,9.46800436167917],[16.0496512255069,15.7654172263479,15.4811832271888,15.1969492280297,14.9127152288707,14.6284812297116,14.3442472305525,14.0600132313934,13.7757792322344,13.4915452330753,13.2073112339162,12.9230772347572,12.6388432355981,12.354609236439,12.0703752372799,11.7861412381209,11.5019072389618,11.2176732398027,10.9334392406437,10.6492052414846,10.3649712423255,10.0807372431664,9.79650324400737,9.5122692448483,9.22803524568923,8.94380124653016],[15.5254481103579,15.2412141111989,14.9569801120398,14.6727461128807,14.3885121137216,14.1042781145626,13.8200441154035,13.5358101162444,13.2515761170854,12.9673421179263,12.6831081187672,12.3988741196081,12.1146401204491,11.83040612129,11.5461721221309,11.2619381229719,10.9777041238128,10.6934701246537,10.4092361254947,10.1250021263356,9.84076812717651,9.55653412801743,9.27230012885836,8.98806612969929,8.70383213054022,8.41959813138115]],"x":[1.513,1.66944,1.82588,1.98232,2.13876,2.2952,2.45164,2.60808,2.76452,2.92096,3.0774,3.23384,3.39028,3.54672,3.70316,3.8596,4.01604,4.17248,4.32892,4.48536,4.6418,4.79824,4.95468,5.11112,5.26756,5.424],"y":[71.1,87.136,103.172,119.208,135.244,151.28,167.316,183.352,199.388,215.424,231.46,247.496,263.532,279.568,295.604,311.64,327.676,343.712,359.748,375.784,391.82,407.856,423.892,439.928,455.964,472],"type":"surface","opacity":0.9,"inherit":true}},"layout":{"margin":{"b":40,"l":60,"t":25,"r":10},"scene":{"xaxis":{"title":"wt"},"yaxis":{"title":"disp"},"zaxis":{"title":"mpg"}},"hovermode":"closest","showlegend":false,"legend":{"yanchor":"top","y":0.5}},"source":"A","config":{"showSendToCloud":false},"data":[{"x":[2.62,2.875,2.32,3.215,3.44,3.46,3.57,3.19,3.15,3.44,3.44,4.07,3.73,3.78,5.25,5.424,5.345,2.2,1.615,1.835,2.465,3.52,3.435,3.84,3.845,1.935,2.14,1.513,3.17,2.77,3.57,2.78],"y":[160,160,108,258,360,225,360,146.7,140.8,167.6,167.6,275.8,275.8,275.8,472,460,440,78.7,75.7,71.1,120.1,318,304,350,400,79,120.3,95.1,351,145,301,121],"z":[21,21,22.8,21.4,18.7,18.1,14.3,24.4,22.8,19.2,17.8,16.4,17.3,15.2,10.4,10.4,14.7,32.4,30.4,33.9,21.5,15.5,15.2,13.3,19.2,27.3,26,30.4,15.8,19.7,15,21.4],"type":"scatter3d","mode":"markers","opacity":0.8,"marker":{"color":"rgba(31,119,180,1)","line":{"color":"rgba(31,119,180,1)"}},"error_y":{"color":"rgba(31,119,180,1)"},"error_x":{"color":"rgba(31,119,180,1)"},"line":{"color":"rgba(31,119,180,1)"},"frame":null},{"colorbar":{"title":"mpg","ticklen":2,"len":0.5,"lenmode":"fraction","y":1,"yanchor":"top"},"colorscale":[["0","rgba(68,1,84,1)"],["0.0416666666666667","rgba(70,19,97,1)"],["0.0833333333333333","rgba(72,32,111,1)"],["0.125","rgba(71,45,122,1)"],["0.166666666666667","rgba(68,58,128,1)"],["0.208333333333333","rgba(64,70,135,1)"],["0.25","rgba(60,82,138,1)"],["0.291666666666667","rgba(56,93,140,1)"],["0.333333333333333","rgba(49,104,142,1)"],["0.375","rgba(46,114,142,1)"],["0.416666666666667","rgba(42,123,142,1)"],["0.458333333333333","rgba(38,133,141,1)"],["0.5","rgba(37,144,140,1)"],["0.541666666666667","rgba(33,154,138,1)"],["0.583333333333333","rgba(39,164,133,1)"],["0.625","rgba(47,174,127,1)"],["0.666666666666667","rgba(53,183,121,1)"],["0.708333333333333","rgba(79,191,110,1)"],["0.75","rgba(98,199,98,1)"],["0.791666666666667","rgba(119,207,85,1)"],["0.833333333333333","rgba(147,214,70,1)"],["0.875","rgba(172,220,52,1)"],["0.916666666666667","rgba(199,225,42,1)"],["0.958333333333333","rgba(226,228,40,1)"],["1","rgba(253,231,37,1)"]],"showscale":true,"z":[[28.6305259890832,28.3462919899241,28.062057990765,27.777823991606,27.4935899924469,27.2093559932878,26.9251219941288,26.6408879949697,26.3566539958106,26.0724199966515,25.7881859974925,25.5039519983334,25.2197179991743,24.9354840000153,24.6512500008562,24.3670160016971,24.082782002538,23.798548003379,23.5143140042199,23.2300800050608,22.9458460059018,22.6616120067427,22.3773780075836,22.0931440084245,21.8089100092655,21.5246760101064],[28.1063228739342,27.8220888747751,27.537854875616,27.253620876457,26.9693868772979,26.6851528781388,26.4009188789797,26.1166848798207,25.8324508806616,25.5482168815025,25.2639828823435,24.9797488831844,24.6955148840253,24.4112808848662,24.1270468857072,23.8428128865481,23.558578887389,23.27434488823,22.9901108890709,22.7058768899118,22.4216428907527,22.1374088915937,21.8531748924346,21.5689408932755,21.2847068941165,21.0004728949574],[27.5821197587852,27.2978857596261,27.013651760467,26.7294177613079,26.4451837621489,26.1609497629898,25.8767157638307,25.5924817646717,25.3082477655126,25.0240137663535,24.7397797671944,24.4555457680354,24.1713117688763,23.8870777697172,23.6028437705582,23.3186097713991,23.03437577224,22.7501417730809,22.4659077739219,22.1816737747628,21.8974397756037,21.6132057764447,21.3289717772856,21.0447377781265,20.7605037789674,20.4762697798084],[27.0579166436362,26.7736826444771,26.489448645318,26.2052146461589,25.9209806469999,25.6367466478408,25.3525126486817,25.0682786495227,24.7840446503636,24.4998106512045,24.2155766520454,23.9313426528864,23.6471086537273,23.3628746545682,23.0786406554092,22.7944066562501,22.510172657091,22.2259386579319,21.9417046587729,21.6574706596138,21.3732366604547,21.0890026612957,20.8047686621366,20.5205346629775,20.2363006638184,19.9520666646594],[26.5337135284871,26.2494795293281,25.965245530169,25.6810115310099,25.3967775318509,25.1125435326918,24.8283095335327,24.5440755343736,24.2598415352146,23.9756075360555,23.6913735368964,23.4071395377374,23.1229055385783,22.8386715394192,22.5544375402601,22.2702035411011,21.985969541942,21.7017355427829,21.4175015436239,21.1332675444648,20.8490335453057,20.5647995461466,20.2805655469876,19.9963315478285,19.7120975486694,19.4278635495104],[26.0095104133381,25.7252764141791,25.44104241502,25.1568084158609,24.8725744167018,24.5883404175428,24.3041064183837,24.0198724192246,23.7356384200656,23.4514044209065,23.1671704217474,22.8829364225883,22.5987024234293,22.3144684242702,22.0302344251111,21.7460004259521,21.461766426793,21.1775324276339,20.8932984284748,20.6090644293158,20.3248304301567,20.0405964309976,19.7563624318386,19.4721284326795,19.1878944335204,18.9036604343613],[25.4853072981891,25.20107329903,24.916839299871,24.6326053007119,24.3483713015528,24.0641373023938,23.7799033032347,23.4956693040756,23.2114353049165,22.9272013057575,22.6429673065984,22.3587333074393,22.0744993082803,21.7902653091212,21.5060313099621,21.221797310803,20.937563311644,20.6533293124849,20.3690953133258,20.0848613141668,19.8006273150077,19.5163933158486,19.2321593166895,18.9479253175305,18.6636913183714,18.3794573192123],[24.9611041830401,24.676870183881,24.392636184722,24.1084021855629,23.8241681864038,23.5399341872448,23.2557001880857,22.9714661889266,22.6872321897675,22.4029981906085,22.1187641914494,21.8345301922903,21.5502961931313,21.2660621939722,20.9818281948131,20.697594195654,20.413360196495,20.1291261973359,19.8448921981768,19.5606581990178,19.2764241998587,18.9921902006996,18.7079562015405,18.4237222023815,18.1394882032224,17.8552542040633],[24.4369010678911,24.152667068732,23.868433069573,23.5841990704139,23.2999650712548,23.0157310720957,22.7314970729367,22.4472630737776,22.1630290746185,21.8787950754595,21.5945610763004,21.3103270771413,21.0260930779822,20.7418590788232,20.4576250796641,20.173391080505,19.889157081346,19.6049230821869,19.3206890830278,19.0364550838687,18.7522210847097,18.4679870855506,18.1837530863915,17.8995190872325,17.6152850880734,17.3310510889143],[23.9126979527421,23.628463953583,23.344229954424,23.0599959552649,22.7757619561058,22.4915279569467,22.2072939577877,21.9230599586286,21.6388259594695,21.3545919603105,21.0703579611514,20.7861239619923,20.5018899628332,20.2176559636742,19.9334219645151,19.649187965356,19.3649539661969,19.0807199670379,18.7964859678788,18.5122519687197,18.2280179695607,17.9437839704016,17.6595499712425,17.3753159720834,17.0910819729244,16.8068479737653],[23.3884948375931,23.104260838434,22.8200268392749,22.5357928401159,22.2515588409568,21.9673248417977,21.6830908426387,21.3988568434796,21.1146228443205,20.8303888451614,20.5461548460024,20.2619208468433,19.9776868476842,19.6934528485252,19.4092188493661,19.124984850207,18.8407508510479,18.5565168518889,18.2722828527298,17.9880488535707,17.7038148544117,17.4195808552526,17.1353468560935,16.8511128569344,16.5668788577754,16.2826448586163],[22.8642917224441,22.580057723285,22.2958237241259,22.0115897249669,21.7273557258078,21.4431217266487,21.1588877274896,20.8746537283306,20.5904197291715,20.3061857300124,20.0219517308534,19.7377177316943,19.4534837325352,19.1692497333761,18.8850157342171,18.600781735058,18.3165477358989,18.0323137367399,17.7480797375808,17.4638457384217,17.1796117392626,16.8953777401036,16.6111437409445,16.3269097417854,16.0426757426264,15.7584417434673],[22.3400886072951,22.055854608136,21.7716206089769,21.4873866098178,21.2031526106588,20.9189186114997,20.6346846123406,20.3504506131816,20.0662166140225,19.7819826148634,19.4977486157043,19.2135146165453,18.9292806173862,18.6450466182271,18.3608126190681,18.076578619909,17.7923446207499,17.5081106215908,17.2238766224318,16.9396426232727,16.6554086241136,16.3711746249546,16.0869406257955,15.8027066266364,15.5184726274773,15.2342386283183],[21.8158854921461,21.531651492987,21.2474174938279,20.9631834946688,20.6789494955098,20.3947154963507,20.1104814971916,19.8262474980326,19.5420134988735,19.2577794997144,18.9735455005553,18.6893115013963,18.4050775022372,18.1208435030781,17.8366095039191,17.55237550476,17.2681415056009,16.9839075064418,16.6996735072828,16.4154395081237,16.1312055089646,15.8469715098056,15.5627375106465,15.2785035114874,14.9942695123283,14.7100355131693],[21.291682376997,21.007448377838,20.7232143786789,20.4389803795198,20.1547463803608,19.8705123812017,19.5862783820426,19.3020443828835,19.0178103837245,18.7335763845654,18.4493423854063,18.1651083862473,17.8808743870882,17.5966403879291,17.31240638877,17.028172389611,16.7439383904519,16.4597043912928,16.1754703921338,15.8912363929747,15.6070023938156,15.3227683946565,15.0385343954975,14.7543003963384,14.4700663971793,14.1858323980203],[20.767479261848,20.483245262689,20.1990112635299,19.9147772643708,19.6305432652117,19.3463092660527,19.0620752668936,18.7778412677345,18.4936072685755,18.2093732694164,17.9251392702573,17.6409052710982,17.3566712719392,17.0724372727801,16.788203273621,16.503969274462,16.2197352753029,15.9355012761438,15.6512672769847,15.3670332778257,15.0827992786666,14.7985652795075,14.5143312803485,14.2300972811894,13.9458632820303,13.6616292828712],[20.243276146699,19.95904214754,19.6748081483809,19.3905741492218,19.1063401500627,18.8221061509037,18.5378721517446,18.2536381525855,17.9694041534265,17.6851701542674,17.4009361551083,17.1167021559492,16.8324681567902,16.5482341576311,16.264000158472,15.979766159313,15.6955321601539,15.4112981609948,15.1270641618357,14.8428301626767,14.5585961635176,14.2743621643585,13.9901281651995,13.7058941660404,13.4216601668813,13.1374261677222],[19.71907303155,19.4348390323909,19.1506050332319,18.8663710340728,18.5821370349137,18.2979030357547,18.0136690365956,17.7294350374365,17.4452010382774,17.1609670391184,16.8767330399593,16.5924990408002,16.3082650416412,16.0240310424821,15.739797043323,15.4555630441639,15.1713290450049,14.8870950458458,14.6028610466867,14.3186270475277,14.0343930483686,13.7501590492095,13.4659250500504,13.1816910508914,12.8974570517323,12.6132230525732],[19.194869916401,18.9106359172419,18.6264019180829,18.3421679189238,18.0579339197647,17.7736999206056,17.4894659214466,17.2052319222875,16.9209979231284,16.6367639239694,16.3525299248103,16.0682959256512,15.7840619264921,15.4998279273331,15.215593928174,14.9313599290149,14.6471259298559,14.3628919306968,14.0786579315377,13.7944239323786,13.5101899332196,13.2259559340605,12.9417219349014,12.6574879357424,12.3732539365833,12.0890199374242],[18.670666801252,18.3864328020929,18.1021988029338,17.8179648037748,17.5337308046157,17.2494968054566,16.9652628062976,16.6810288071385,16.3967948079794,16.1125608088204,15.8283268096613,15.5440928105022,15.2598588113431,14.9756248121841,14.691390813025,14.4071568138659,14.1229228147069,13.8386888155478,13.5544548163887,13.2702208172296,12.9859868180706,12.7017528189115,12.4175188197524,12.1332848205933,11.8490508214343,11.5648168222752],[18.146463686103,17.8622296869439,17.5779956877848,17.2937616886258,17.0095276894667,16.7252936903076,16.4410596911486,16.1568256919895,15.8725916928304,15.5883576936713,15.3041236945123,15.0198896953532,14.7356556961941,14.4514216970351,14.167187697876,13.8829536987169,13.5987196995578,13.3144857003988,13.0302517012397,12.7460177020806,12.4617837029216,12.1775497037625,11.8933157046034,11.6090817054443,11.3248477062853,11.0406137071262],[17.622260570954,17.3380265717949,17.0537925726358,16.7695585734768,16.4853245743177,16.2010905751586,15.9168565759995,15.6326225768405,15.3483885776814,15.0641545785223,14.7799205793633,14.4956865802042,14.2114525810451,13.927218581886,13.642984582727,13.3587505835679,13.0745165844088,12.7902825852498,12.5060485860907,12.2218145869316,11.9375805877725,11.6533465886135,11.3691125894544,11.0848785902953,10.8006445911363,10.5164105919772],[17.098057455805,16.8138234566459,16.5295894574868,16.2453554583277,15.9611214591687,15.6768874600096,15.3926534608505,15.1084194616915,14.8241854625324,14.5399514633733,14.2557174642142,13.9714834650552,13.6872494658961,13.403015466737,13.118781467578,12.8345474684189,12.5503134692598,12.2660794701007,11.9818454709417,11.6976114717826,11.4133774726235,11.1291434734645,10.8449094743054,10.5606754751463,10.2764414759872,9.99220747682818],[16.573854340656,16.2896203414969,16.0053863423378,15.7211523431787,15.4369183440197,15.1526843448606,14.8684503457015,14.5842163465425,14.2999823473834,14.0157483482243,13.7315143490652,13.4472803499062,13.1630463507471,12.878812351588,12.594578352429,12.3103443532699,12.0261103541108,11.7418763549517,11.4576423557927,11.1734083566336,10.8891743574745,10.6049403583155,10.3207063591564,10.0364723599973,9.75223836083824,9.46800436167917],[16.0496512255069,15.7654172263479,15.4811832271888,15.1969492280297,14.9127152288707,14.6284812297116,14.3442472305525,14.0600132313934,13.7757792322344,13.4915452330753,13.2073112339162,12.9230772347572,12.6388432355981,12.354609236439,12.0703752372799,11.7861412381209,11.5019072389618,11.2176732398027,10.9334392406437,10.6492052414846,10.3649712423255,10.0807372431664,9.79650324400737,9.5122692448483,9.22803524568923,8.94380124653016],[15.5254481103579,15.2412141111989,14.9569801120398,14.6727461128807,14.3885121137216,14.1042781145626,13.8200441154035,13.5358101162444,13.2515761170854,12.9673421179263,12.6831081187672,12.3988741196081,12.1146401204491,11.83040612129,11.5461721221309,11.2619381229719,10.9777041238128,10.6934701246537,10.4092361254947,10.1250021263356,9.84076812717651,9.55653412801743,9.27230012885836,8.98806612969929,8.70383213054022,8.41959813138115]],"x":[1.513,1.66944,1.82588,1.98232,2.13876,2.2952,2.45164,2.60808,2.76452,2.92096,3.0774,3.23384,3.39028,3.54672,3.70316,3.8596,4.01604,4.17248,4.32892,4.48536,4.6418,4.79824,4.95468,5.11112,5.26756,5.424],"y":[71.1,87.136,103.172,119.208,135.244,151.28,167.316,183.352,199.388,215.424,231.46,247.496,263.532,279.568,295.604,311.64,327.676,343.712,359.748,375.784,391.82,407.856,423.892,439.928,455.964,472],"type":"surface","opacity":0.9,"frame":null}],"highlight":{"on":"plotly_click","persistent":false,"dynamic":false,"selectize":false,"opacityDim":0.2,"selected":{"opacity":1},"debounce":0},"shinyEvents":["plotly_hover","plotly_click","plotly_selected","plotly_relayout","plotly_brushed","plotly_brushing","plotly_clickannotation","plotly_doubleclick","plotly_deselect","plotly_afterplot","plotly_sunburstclick"],"base_url":"https://plot.ly"},"evals":[],"jsHooks":[]}</script>


---

## Preditores Categóricos

### Preditor com apenas 2 categorias

Saldo médio no cartão de crédito é diferente entre homens e mulheres?

![](02-regressao-linear_files/figure-html/unnamed-chunk-26-1.png)&lt;!-- --&gt;


```r
summary(lm(Balance ~ Gender, data = Credit))
# Coefficients:
#              Estimate  Std.Error  t value Pr(&gt;|t|)    
# (Intercept)    509.80  33.13      15.389   &lt;2e-16 ***
# GenderFemale    19.73  46.05       0.429    0.669   
```


.footnote[
Ver [ISL](https://www.ime.unicamp.br/~dias/Intoduction%20to%20Statistical%20Learning.pdf) página 84 (Predictors with Only Two Levels).
]


---

## Preditores Categóricos

### Preditor com apenas 2 categorias

Saldo médio no cartão de crédito é diferente entre homens e mulheres?

![](02-regressao-linear_files/figure-html/unnamed-chunk-28-1.png)&lt;!-- --&gt;


$$
y_i = \beta_0 + \beta_1x_i \space\space\space\space\space\space \text{em que}\space\space\space\space\space\space x_i = \Bigg\\{\begin{array}{ll}1&amp;\text{se a i-ésima pessoa for }\texttt{female}\\\\
0&amp;\text{se a i-ésima pessoa for } \texttt{male}\end{array}
$$


```r
# lembrete: exercícios 8, 9 e 10 do script!
```


.footnote[
Ver [ISL](https://www.ime.unicamp.br/~dias/Intoduction%20to%20Statistical%20Learning.pdf) página 84 (Predictors with Only Two Levels).
]


---

## Preditores Categóricos

### Preditor com 3 ou mais categorias

.pull-left[

![](02-regressao-linear_files/figure-html/unnamed-chunk-30-1.png)&lt;!-- --&gt;



```r
summary(lm(Balance ~ Ethnicity, data = Credit))
#                    Estimate  Std.Error t value Pr(&gt;|t|)    
# (Intercept)          531.00  46.32     11.464   &lt;2e-16 ***
# EthnicityAsian       -18.69  65.02     -0.287    0.774    
# EthnicityCaucasian   -12.50  56.68     -0.221    0.826  
```


]

.pull-right[

Modelo

`$$y_i = \beta_0 + \beta_1x_{1i} + \beta_2x_{2i}$$`

Em que


`\(x_{1i} = \Bigg \{ \begin{array}{ll} 1 &amp; \text{se for }\texttt{Asian}\\0&amp;\text{caso contrário}\end{array}\)`

`\(x_{2i} = \Bigg \{ \begin{array}{ll} 1 &amp; \text{se for }\texttt{Caucasian}\\0&amp;\text{caso contrário}\end{array}\)`

]


---

## Preditores Categóricos

### Preditor com 3 ou mais categorias

"One hot enconding" ou "Dummies" ou "Indicadores".

&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; Ethnicity &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; (Intercept) &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; EthnicityAsian &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; EthnicityCaucasian &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Caucasian &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Asian &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Asian &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Asian &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Caucasian &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Caucasian &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; African American &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Asian &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

---

## Preditores Categóricos

### Preditor com 3 ou mais categorias

Interpretação dos parâmetros:

`\(y_{i} = \left\{ \begin{array}{ll} \beta_0 &amp; \text{se for }\texttt{Afro American}\\ \beta_0 + \beta_1&amp;\text{se for } \texttt{Asian}\\ \beta_0 + \beta_2&amp;\text{se for } \texttt{Caucasian}\end{array}\right.\)`


```r
# interprete cada um dos três parâmetros individualmente.
# lembrete: exercício 11 do script!
```


---

## Transformações Não Lineares dos Preditores

### Exemplo: log

.pull-left[
Modelo real: `\(y = 10 + 0.5log(x)\)` 
]

.pull-right[
Modelo proposto: `\(\small y = \beta_0 + \beta_1log(x)\)` 
]


&lt;img src="02-regressao-linear_files/figure-html/unnamed-chunk-35-1.png" style="display: block; margin: auto;" /&gt;

Outras transformações comuns: raíz quadrada, polinômios, Box-Cox, ...


```r
# lembrete: exercício 13 do script!
```


---

## Transformações Não Lineares dos Preditores

### Exemplo: log


.pull-left[
Modelo real: `\(y = 10 + 0.5log(x)\)` 
]

.pull-right[
Modelo proposto: `\(\small y = \beta_0 + \beta_1log(x)\)` 
]

&lt;img src="02-regressao-linear_files/figure-html/unnamed-chunk-37-1.png" style="display: block; margin: auto;" /&gt;

Outras transformações comuns: raíz quadrada, polinômios, Box-Cox, ...


```r
# lembrete: exercício 13 do script!
```


---

## Transformações Não Lineares dos Preditores

### Gráfico de Resíduos
&lt;img src="02-regressao-linear_files/figure-html/unnamed-chunk-39-1.png" style="display: block; margin: auto;" /&gt;


---

## Transformações Não Lineares dos Preditores

### Exemplo: Regressão Polinomial

.pull-left[
Modelo real: `\(y = 500 + 0.4(x-10)^3\)` 

![](02-regressao-linear_files/figure-html/unnamed-chunk-40-1.png)&lt;!-- --&gt;

]

.pull-right[
Modelo proposto: `\(y = \beta_0 + \beta_1x + \beta_2x^2 + \beta_3x^3\)` 


![](02-regressao-linear_files/figure-html/unnamed-chunk-41-1.png)&lt;!-- --&gt;

]




```r
# lembrete: exercício 14 do script!
```

---

## Transformações Não Lineares dos Preditores

### Exemplo: Regressão Polinomial

.pull-left[
Modelo real: `\(y = 500 + 0.4(x-10)^3\)` 


![](02-regressao-linear_files/figure-html/unnamed-chunk-43-1.png)&lt;!-- --&gt;

]

.pull-right[
Modelo proposto: `\(y = \beta_0 + \beta_1x + \beta_2x^2 + \beta_3x^3\)` 

&lt;table class="table" style="font-size: 16px; margin-left: auto; margin-right: auto;"&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:right;"&gt; y &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; x &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; x2 &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; x3 &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 456.5 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 5.3 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 28.2 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 149.7 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 492.5 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 7.4 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 55.4 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 412.2 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 548.4 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 11.5 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 131.3 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1503.9 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 758.7 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 18.2 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 329.9 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 5993.0 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 444.7 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 4.0 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 16.3 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 65.6 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 748.3 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 18.0 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 322.8 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 5800.8 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 820.5 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 18.9 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 357.0 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 6744.3 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

]



```r
# lembrete: exercício 13 do script!
```


---


## Transformações Não Lineares dos Preditores

### Gráfico de Resíduos
&lt;img src="02-regressao-linear_files/figure-html/unnamed-chunk-46-1.png" style="display: block; margin: auto;" /&gt;


---

## Interações

Interação entre duas variáveis explicativas: `Species` e `Sepal.Length`

&lt;img src="02-regressao-linear_files/figure-html/unnamed-chunk-47-1.png" height="330" style="display: block; margin: auto;" /&gt;



---

## Interações

Modelo proposto (Matemático): Seja `y = Sepal.Width` e `x = Sepal.Length`,

`$$\small \begin{array}{l} y = \beta_0 + \beta_1x\end{array}$$`



&lt;img src="02-regressao-linear_files/figure-html/unnamed-chunk-48-1.png" height="260" style="display: block; margin: auto;" /&gt;


Modelo proposto (em R): `Sepal.Width ~ Sepal.Length`


```r
# lembrete: exercícios 14 ao 17 do script!
```

---

## Interações

Modelo proposto (Matemático): Seja `y = Sepal.Width` e `x = Sepal.Length`,

`$$\small \begin{array}{l} y = \beta_0 + \beta_1x + \beta_2I_{versicolor} + \beta_3I_{virginica}\end{array}$$`


&lt;img src="02-regressao-linear_files/figure-html/unnamed-chunk-50-1.png" height="260" style="display: block; margin: auto;" /&gt;


Modelo proposto (em R): `Sepal.Width ~ Sepal.Length + Species`


```r
# lembrete: exercícios 14 ao 17 do script!
```


---

## Interações

Modelo proposto (Matemático): Seja `y = Sepal.Width` e `x = Sepal.Length`,

`$$\small \begin{array}{l} y = \beta_0 + \beta_1x + \beta_2I_{versicolor} + \beta_3I_{virginica} + \beta_4\color{red}{xI_{versicolor}} + \beta_5\color{red}{xI_{virginica}}\end{array}$$`


&lt;img src="02-regressao-linear_files/figure-html/unnamed-chunk-52-1.png" height="260" style="display: block; margin: auto;" /&gt;


Modelo proposto (em R): `Sepal.Width ~ Sepal.Length * Species`


```r
# lembrete: exercícios 14 ao 17 do script!
```

---

## Heterocedasticidade

![](02-regressao-linear_files/figure-html/unnamed-chunk-54-1.png)&lt;!-- --&gt;

---

## Heterocedasticidade


![](02-regressao-linear_files/figure-html/unnamed-chunk-55-1.png)&lt;!-- --&gt;



---

## Heterocedasticidade

![](02-regressao-linear_files/figure-html/unnamed-chunk-56-1.png)&lt;!-- --&gt;



---

## Heterocedasticidade

### Problema

- O estimador 
`\(\hat{\sigma}_{\beta_1} = \sqrt{\frac{EQM}{\sum(x_i - \bar{x})^2}}\)` deixa de ter as melhores propriedades. Poderíamos ter conclusões estranhas para `\(\beta_1\)`.

### Diagnóstico

- Visualização dos resíduos;

### Tratamentos

- Transformações na variável resposta. log(y), sqrt(y), 1/y, etc;


---

## Multicolinearidade

.pull-left[

![](02-regressao-linear_files/figure-html/unnamed-chunk-57-1.png)&lt;!-- --&gt;

]

.pull-right[

Modelo 1: sem colineares

&lt;table class="table" style="font-size: 13px; margin-left: auto; margin-right: auto;"&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; term &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; estimate &lt;/th&gt;
   &lt;th style="text-align:left;"&gt; std.error &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; statistic &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; p.value &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; (Intercept) &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -173.41 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; &lt;span style="     color: black !important;padding-right: 4px; padding-left: 4px; background-color: white !important;text-align: r;"&gt;43.83&lt;/span&gt; &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -3.96 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Limit &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.17 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; &lt;span style="     color: white !important;padding-right: 4px; padding-left: 4px; background-color: darkred !important;text-align: r;"&gt;0.01&lt;/span&gt; &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 34.50 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Age &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -2.29 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; &lt;span style="     color: black !important;padding-right: 4px; padding-left: 4px; background-color: white !important;text-align: r;"&gt;0.67&lt;/span&gt; &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -3.41 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

Modelo 2: com colineares

&lt;table class="table" style="font-size: 13px; margin-left: auto; margin-right: auto;"&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; term &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; estimate &lt;/th&gt;
   &lt;th style="text-align:left;"&gt; std.error &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; statistic &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; p.value &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; (Intercept) &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -377.54 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; &lt;span style="     color: black !important;padding-right: 4px; padding-left: 4px; background-color: white !important;text-align: r;"&gt;45.25&lt;/span&gt; &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -8.34 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.00 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Limit &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.02 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; &lt;span style="     color: white !important;padding-right: 4px; padding-left: 4px; background-color: darkred !important;text-align: r;"&gt;0.06&lt;/span&gt; &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.38 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.70 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Rating &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 2.20 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; &lt;span style="     color: black !important;padding-right: 4px; padding-left: 4px; background-color: white !important;text-align: r;"&gt;0.95&lt;/span&gt; &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 2.31 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.02 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

]

Problema: Instabilidade numérica, desvios padrão inflados e interpretação comprometida.

Soluções: eliminar uma das variáveis muito correlacionadas ou Consultar o VIF (Variance Inflation Factor)

---

## Multicolinearidade

### VIF (Variance Inflation Factor)

Detecta preditores que são combinações lineares de outros preditores.


**Procedimento:** Para cada preditor `\(X_j\)`,

1) Ajusta regressão linear com as demais: `lm(X_j ~ X_1 + ... + X_p)`.

2) Calcula-se o R-quadrado dessa regressão e aplica a fórmula abaixo

`$$\small VIF(\hat{\beta}_j) = \frac{1}{1 - R^2_{X_j|X_{-j}}}$$`

3) Remova o preditor se VIF maior que 5 (regra de bolso).


```r
# lembrete: exercícios 18 do script!
```



.footnote[
Ver [ISL](https://www.ime.unicamp.br/~dias/Intoduction%20to%20Statistical%20Learning.pdf) página 101.
]


---

## Fazendo Predições

### Modelo


```r
modelo_iris &lt;- lm(Sepal.Width ~ Sepal.Length * Species, data = iris)
```

Suponha que dados novos chegaram:


```r
dados_novos &lt;- tibble(Sepal.Length = 10, Species = "setosa")
```


### Utilizando a função `augment()` do pacote `broom`


```r
augment(modelo_iris, newdata = dados_novos)
##   Sepal.Length Species .fitted .se.fit
## 1           10 setosa     7.42   0.553
```

O valor estimado de `Sepal.Width` foi de `7.42` +/- `0.55`.


---

## Fazendo Predições

### Modelo


```r
modelo_iris &lt;- lm(Sepal.Width ~ Sepal.Length * Species, data = iris)
```

Suponha que dados novos chegaram:


```r
dados_novos &lt;- data.frame(Sepal.Length = 10, Species = "setosa")
```


### Utilizando a função `predict()`


```r
dados_novos %&gt;% 
  mutate(S.W.Est = predict(modelo_iris, newdata = dados_novos))
##  Sepal.Length Species S.W.Est
##            10 setosa     7.42
```


---

## Interpretabilidade da Predição

### LIME: Local Interpretable Model-agnostic Explanations





```r
# fazendo lm com caret::train() pq o lime soh aceita caret
modelo_iris &lt;- train(Sepal.Width ~ Sepal.Length * Species, data = iris, method = "lm")
explicador &lt;- lime(iris, modelo_iris)
explicacoes &lt;- lime::explain(dados_novos, explicador, n_features = 2)
plot_features(explicacoes) 
```

.pull-left[


```r
# lembrete: exercícios 19 
# do script!
```

]

.pull-right[

![](02-regressao-linear_files/figure-html/unnamed-chunk-70-1.png)&lt;!-- --&gt;

]


.footnote[
Ver [LIME for R](https://github.com/thomasp85/lime) página 101.
]


---

## (Opcional) Abordagem Probabilística

Do ponto de vista probabilístico, modela-se o problema como uma amostra de N indivíduos, todos independentes entre si e com distribuição Normal.

$$
Y_i|x_i \sim N(\mu_i, \sigma^2), \space i = 1, \dots, N
$$

E então, supõem que a média de `\(Y\)` dado o valor de `\(x\)` seja linear:

$$
\mu = E[Y|x] = \beta_0 + \beta_1x
$$

Assim, gostaríamos de achar `\(\beta_0\)` e `\(\beta_1\)` que fizessem dessa amostra a mais verossímil possível. 

Daí entra o conceito de verossimilhança, que é a probabilidade conjunta dos dados acontecerem:

$$
P(Y_1, \dots, Y_N|x) \overset{\text{indep}}{=} P(Y_1|x_1)P(Y_2|x_2)\dots P(Y_N|x_N)
$$

continua...


---

## (Opcional) Abordagem Probabilística

Se tirarmos o `\(logarítmo\)` dessa probabilidade conjunta, teremos:

$$
logP(Y_1, \dots, Y_N|x) \overset{\text{indep}}{=} logP(Y_i|x_1) + log P(Y_2|x_2) +\dots +logP(Y_N|x_N)
$$

Que podemos escrever de forma mais sussinta usando um somatório:

`$$\ell = logP(Y_1, \dots, Y_N|x) = \sum_{i = 1}^{N}logP(Y_i|x_i)$$`

Essa expressão que chamamos de `\(\ell\)` é conhecida como log-verossimilhança (log-likelihood no inglês).

continua...


---

## (Opcional) Abordagem Probabilística

Já que assumimos que `\(Y_i|x_i\)` segue uma distribuição `\(N(\beta_0 + \beta_1x_i, \sigma^2)\)`, temos que:

$$
\ell =  \sum_{i = 1}^{N}log\left(\frac{1}{\sqrt{2\pi\sigma^2}}\exp\left[-\frac{1}{2\sigma^2}(y_i - \mu_i)^2 \right] \right)
$$

Que depois de simplificar (e deixando as constantes de fora), fica

`$$\ell = -\frac{1}{N}\sum(y_i - \mu_i)^2 = -\frac{1}{N}\sum(y_i -  \color{red}{(\beta_0 + \beta_1speed)})^2 = -EQM$$`

Ou seja, maximizar a verossimilhança é equivalente a minimizar o EQM como vínhamos fazendo.

---

## Questões importantes

Questões que usualmente estamos interessados quando ajustamos uma regressão linear.

- Pelo menos um dos preditores  `\(X1, X2,\dots,X_p\)` é útil para prever/explicar?

- Todos os preditores são úteis ou apenas um subconjunto deles que é?

- O quão bem o modelo se ajusta aos dados?

.footnote[
Ver [ISL](https://www.ime.unicamp.br/~dias/Intoduction%20to%20Statistical%20Learning.pdf) página 75 (Some Important Questions).
]


---

## Sobreajuste (overfitting)

Modelo real é de **grau 3**

![distrib_params](img/overfiting_sem_teste.gif)

---

## Sobreajuste (overfitting)

Modelo real é de **grau 3**

![distrib_params](img/overfiting_com_teste.gif)

---

## Sobreajuste (overfitting)

Modelo real é de **grau 3**

![scatter_eqm](img/overfiting_scatter_eqm.gif)

.footnote[
Ver [ISL](https://www.ime.unicamp.br/~dias/Intoduction%20to%20Statistical%20Learning.pdf) página 61 (Simple Linear Regression).
]


---

## Regularização

Relembrando o nossa **função de custo** EQM.

`$$EQM = \frac{1}{N}\sum(y_i - \hat{y_i})^2 = \frac{1}{N}\sum(y_i -  \color{red}{(\hat{\beta}_0 + \hat{\beta}_1x_{1i} + \dots + \hat{\beta}_px_{pi})})^2$$`

Regularizar é "não deixar os `\(\beta's\)` soltos demais".

`$$EQM_{regularizado} = EQM + \color{red}{\lambda}\sum_{j = 1}^{p}|\beta_j|$$`

Ou seja, **penalizamos** a função de custo se os `\(\beta's\)` forem muito grandes.

.footnote[
Ver [ISL](https://www.ime.unicamp.br/~dias/Intoduction%20to%20Statistical%20Learning.pdf) página 203 (Linear Model Selection and Regularization).
]


---

## LASSO e Seleção de Preditores

Conforme aumentamos o `\(\color{red}{\lambda}\)`, forçamos os `\(\beta's\)` a serem cada vez menores.


![scatter_eqm](img/lasso_lambda.png)

.footnote[
Ver [ISL](https://www.ime.unicamp.br/~dias/Intoduction%20to%20Statistical%20Learning.pdf) página 219 (The LASSO).
]


---

## LASSO e Seleção de Preditores

Conforme aumentamos o `\(\lambda\)`, forçamos os `\(\beta's\)` a serem cada vez menores.


![scatter_eqm](img/betas.png)


.footnote[
Ver [ISL](https://www.ime.unicamp.br/~dias/Intoduction%20to%20Statistical%20Learning.pdf) página 219 (The LASSO).
]

---

## Validação Cruzada


```
## #  5-fold cross-validation 
## # A tibble: 5 x 6
##   splits          id    n_treino n_teste regressao eqm_teste
##   &lt;list&gt;          &lt;chr&gt;    &lt;dbl&gt;   &lt;dbl&gt; &lt;list&gt;        &lt;dbl&gt;
## 1 &lt;split [40/10]&gt; Fold1       40      10 &lt;lm&gt;           17.0
## 2 &lt;split [40/10]&gt; Fold2       40      10 &lt;lm&gt;           13.0
## 3 &lt;split [40/10]&gt; Fold3       40      10 &lt;lm&gt;           12.2
## 4 &lt;split [40/10]&gt; Fold4       40      10 &lt;lm&gt;           15.7
## 5 &lt;split [40/10]&gt; Fold5       40      10 &lt;lm&gt;           19.6
```


```
## [1] 15.494
```


ERRO DE VALIDAÇÃO CRUZADA: `$$EQM_{cv} = \frac{1}{10}\sum_{i=1}^{10}EQM_{Fold_i} = 14,671$$`

---

## Validação Cruzada

&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; fold &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; speed &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; dist &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;background-color: #F8766D !important;"&gt; fold 1 &lt;/td&gt;
   &lt;td style="text-align:right;background-color: #F8766D !important;"&gt; 4 &lt;/td&gt;
   &lt;td style="text-align:right;background-color: #F8766D !important;"&gt; 2 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;background-color: #F8766D !important;"&gt; fold 1 &lt;/td&gt;
   &lt;td style="text-align:right;background-color: #F8766D !important;"&gt; 4 &lt;/td&gt;
   &lt;td style="text-align:right;background-color: #F8766D !important;"&gt; 10 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;background-color: #D39200 !important;"&gt; fold 2 &lt;/td&gt;
   &lt;td style="text-align:right;background-color: #D39200 !important;"&gt; 7 &lt;/td&gt;
   &lt;td style="text-align:right;background-color: #D39200 !important;"&gt; 4 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;background-color: #D39200 !important;"&gt; fold 2 &lt;/td&gt;
   &lt;td style="text-align:right;background-color: #D39200 !important;"&gt; 7 &lt;/td&gt;
   &lt;td style="text-align:right;background-color: #D39200 !important;"&gt; 22 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;background-color: #93AA00 !important;"&gt; fold 3 &lt;/td&gt;
   &lt;td style="text-align:right;background-color: #93AA00 !important;"&gt; 8 &lt;/td&gt;
   &lt;td style="text-align:right;background-color: #93AA00 !important;"&gt; 16 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;background-color: #93AA00 !important;"&gt; fold 3 &lt;/td&gt;
   &lt;td style="text-align:right;background-color: #93AA00 !important;"&gt; 9 &lt;/td&gt;
   &lt;td style="text-align:right;background-color: #93AA00 !important;"&gt; 10 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;background-color: #00BA38 !important;"&gt; fold 4 &lt;/td&gt;
   &lt;td style="text-align:right;background-color: #00BA38 !important;"&gt; 10 &lt;/td&gt;
   &lt;td style="text-align:right;background-color: #00BA38 !important;"&gt; 18 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;background-color: #00BA38 !important;"&gt; fold 4 &lt;/td&gt;
   &lt;td style="text-align:right;background-color: #00BA38 !important;"&gt; 10 &lt;/td&gt;
   &lt;td style="text-align:right;background-color: #00BA38 !important;"&gt; 26 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;background-color: #00C19F !important;"&gt; fold 5 &lt;/td&gt;
   &lt;td style="text-align:right;background-color: #00C19F !important;"&gt; 10 &lt;/td&gt;
   &lt;td style="text-align:right;background-color: #00C19F !important;"&gt; 34 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;background-color: #00C19F !important;"&gt; fold 5 &lt;/td&gt;
   &lt;td style="text-align:right;background-color: #00C19F !important;"&gt; 11 &lt;/td&gt;
   &lt;td style="text-align:right;background-color: #00C19F !important;"&gt; 17 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

---

## Limitações da Regressão Linear

- Variável resposta Não Normal
- Variável resposta Positiva
- Variável resposta Categórica
- Relação funcional não linear entre X e Y
- Muitas interações para testar entre as preditoras
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
